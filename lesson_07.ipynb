{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# :cook: <font color=\"orange\">Inferring</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, you will infer sentiment and topics from product reviews and news articles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-Yuu6ZbvcrmJ6aYp5IUQiT3BlbkFJMcylU\n",
      "First LLM API example\n",
      "‚úÖ OpenAI Key loaded (sk-Yuu6ZbvcrmJ6aYp5IUQiT3BlbkFJMcylU...)\n"
     ]
    }
   ],
   "source": [
    "from util import local_settings\n",
    "from env_colors import TerminalTextColor as ttc\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"First LLM API example\")\n",
    "print(f\"‚úÖ OpenAI Key loaded ({local_settings.OPENAI_API_KEY[0:-15]}...)\")\n",
    "\n",
    "client = OpenAI(api_key=local_settings.OPENAI_API_KEY)\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0, messages=None):\n",
    "    if not messages:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A product review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had\n",
    "additional storage and not too high of a price point.\n",
    "Got it fast.  The string to our lamp broke during the\n",
    "transit and the company happily sent over a new one.\n",
    "Came within a few days as well. It was easy to put\n",
    "together.  I had a missing part, so I contacted their\n",
    "support and they very quickly got me the missing piece!\n",
    "Lumina seems to me to be a great company that cares\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extract a sentiment, positive or negative, of a piece of text, in the traditional machine learning workflow, you'd have to collect the label data set, train\n",
    "a model, figure out how to deploy the model somewhere in the cloud and make inferences. \n",
    "\n",
    "And that could work pretty well, but it was, you know, just a lot of work to go through that process. \n",
    "\n",
    "And also for every task, such as sentiment versus extracting names versus\n",
    "something else, you have to train and deploy a separate model. One of the really nice\n",
    "things about large language model is that for many tasks like these, you can just write a prompt and have it start generating results pretty much right away. \n",
    "\n",
    "And that gives tremendous speed in terms of application development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Review (Text) ---\n",
      "\n",
      "Needed a nice lamp for my bedroom, and this one had\n",
      "additional storage and not too high of a price point.\n",
      "Got it fast.  The string to our lamp broke during the\n",
      "transit and the company happily sent over a new one.\n",
      "Came within a few days as well. It was easy to put\n",
      "together.  I had a missing part, so I contacted their\n",
      "support and they very quickly got me the missing piece!\n",
      "Lumina seems to me to be a great company that cares \n",
      "about their customers and products!!\n",
      "\n",
      "--- Sentiment ---\n",
      "The sentiment of the product review is positive.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Review (Text) ---\")\n",
    "print(lamp_review)\n",
    "\n",
    "print(\"--- Sentiment ---\")\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concise response - Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to give a more concise response to make it easier for post-processing, I can take this prompt and add another instruction to give you answers to a single word, either positive or negative. So it just prints out positive like this, which makes it easier for a piece of text to take this output and process it and do something with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ñ So, large language models are pretty good at extracting specific things out of a piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify types of emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\"...Identify a list of emotions that the writer of the following review is expressing. Include no more than five items in this list.\"```\n",
    "\n",
    "So, large language models are pretty good at extracting specific things out of a piece of text.\n",
    "\n",
    "For a lot of customer support organizations, it's important to understand if a particular user is extremely upset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy, satisfied, impressed, grateful, pleased\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Identify anger</font> :raised_eyebrow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "text = \"This lamp from the website is a total disaster! Shoddy build quality, false brightness claims, and a nightmare assembly process. Customer service is nonexistent. Save your money and sanity ‚Äì avoid this deceptive purchase. There are better options elsewhere that won't leave you regretting every penny spent.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{text}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract <font color=\"cyan\">product</font>  and <font color=\"cyan\">company name </font> from customer reviews\n",
    "\n",
    ":point_right: information extraction is the part of NLP that relates to taking a piece of text and extracting certain things that you want to know from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to ask it to format your response as a JSON object with \"Item\" and \"Brand\" as the keys. \n",
    "\n",
    "And so if I do that, it says the item is a lamp, the brand is Lumina, and you can easily load this into the Python dictionary to then do additional processing on this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REVIEW (Text) ---\n",
      "\n",
      "Needed a nice lamp for my bedroom, and this one had\n",
      "additional storage and not too high of a price point.\n",
      "Got it fast.  The string to our lamp broke during the\n",
      "transit and the company happily sent over a new one.\n",
      "Came within a few days as well. It was easy to put\n",
      "together.  I had a missing part, so I contacted their\n",
      "support and they very quickly got me the missing piece!\n",
      "Lumina seems to me to be a great company that cares \n",
      "about their customers and products!!\n",
      "\n",
      "--- RESPONSE ---\n",
      "{\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks.\n",
    "\n",
    "Format your response as a JSON object with\n",
    "\"Item\" and \"Brand\" as the keys.\n",
    "\n",
    "If the information isn't present, use \"unknown\"\n",
    "as the value.\n",
    "\n",
    "Make your response as short as possible.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- REVIEW (Text) ---\")\n",
    "print(lamp_review)\n",
    "\n",
    "print(f\"--- RESPONSE ---\")\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"cyan\">Doing multiple tasks at once</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's say ```identify the following items, extract sentiment, is the reviewer expressing anger, item purchased, company that made it```.\n",
    "\n",
    "Then here I'm also going to tell it to format the anger value as a boolean value, and let me run that. And this outputs a JSON where sentiment is positive, anger, and then no quotes around false because it asked it to just output it as a boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks.\n",
    "Format your response as a JSON object with\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "\n",
    "If the information isn't present, use \"unknown\"\n",
    "as the value.\n",
    "\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"cyan\">Inferring Topics</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":point_right:  one of the cool applications I've seen of large language models is __**inferring topics**__. \n",
    "\n",
    "Given a long piece of text:\n",
    "- what is this piece of text about? \n",
    "- What are the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government,\n",
    "public sector employees were asked to rate their level\n",
    "of satisfaction with the department they work at.\n",
    "The results revealed that NASA was the most popular\n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings,\n",
    "stating, \"I'm not surprised that NASA came out on top.\n",
    "It's a great place to work with amazing people and\n",
    "incredible opportunities. I'm proud to be a part of\n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team,\n",
    "with Director Tom Johnson stating, \"We are thrilled to\n",
    "hear that our employees are satisfied with their work at NASA.\n",
    "We have a talented and dedicated team who work tirelessly\n",
    "to achieve our goals, and it's fantastic to see that their\n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the\n",
    "Social Security Administration had the lowest satisfaction\n",
    "rating, with only 45% of employees indicating they were\n",
    "satisfied with their job. The government has pledged to\n",
    "address the concerns raised by employees in the survey and\n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey, Satisfaction, NASA, Social Security Administration, Job satisfaction\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long.\n",
    "\n",
    "Output format:\n",
    "Format your response as a list of items separated by commas like this:\n",
    "Topic 1, Topic 2, ..., Topic n\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survey',\n",
       " ' Satisfaction',\n",
       " ' NASA',\n",
       " ' Social Security Administration',\n",
       " ' Job satisfaction']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list = response.split(sep=',')\n",
    "\n",
    "topic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíä <font color=\"cyan\">Make a news alert for certain topics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nasa',\n",
       " 'Artificial Intelligence',\n",
       " 'Medicine',\n",
       " 'employee satisfaction',\n",
       " 'federal government']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list = [\n",
    "    \"Nasa\",\n",
    "    \"Artificial Intelligence\", # <--\n",
    "    \"Medicine\",             # <--\n",
    "    \"employee satisfaction\",\n",
    "    \"federal government\"\n",
    "]\n",
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of response: <class 'str'>\n",
      "Type of r_list:   <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_list = eval(response)\n",
    "\n",
    "print(f\"Type of response: {type(response)}\")\n",
    "print(f\"Type of r_list:   {type(r_list)}\")\n",
    "\n",
    "r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nasa': 1, 'Artificial Intelligence': 0, 'Medicine': 0, 'employee satisfaction': 1, 'federal government': 1}\n",
      "ALERT: New NASA story!\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {topic_list[i]: int(r_list[i]) for i in range(len(topic_list))}\n",
    "\n",
    "print(topic_dict)\n",
    "\n",
    "if topic_dict['Nasa'] == 1:\n",
    "    print(\"ALERT: New NASA story!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
